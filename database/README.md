# Database

This folder contains AlloyDB schema definitions and seeding scripts.

## Contents

- `seed_data.sql` - SQL for AlloyDB Studio: schema, 20 sample items, `ai.embedding()`, and ScaNN index
- `seed.py` - Backup Python script to seed data (uses AlloyDB Python Connector)
- `requirements.txt` - Python dependencies (google-cloud-alloydb-connector, pg8000)

## Schema

The `inventory` table stores parts with vector embeddings for semantic search:

```sql
CREATE TABLE inventory (
    id SERIAL PRIMARY KEY,
    part_name TEXT NOT NULL,
    supplier_name TEXT NOT NULL,
    description TEXT,
    stock_level INT DEFAULT 0,
    part_embedding vector(768)  -- text-embedding-005 dimension
);

-- ScaNN index for fast vector search
CREATE INDEX idx_inventory_scann
ON inventory USING scann (part_embedding cosine)
WITH (num_leaves=5, quantizer='sq8');
```

## ScaNN Index

**ScaNN (Scalable Nearest Neighbors)** uses vector quantization for:
- **10x faster** filtered search
- **4x faster** standard search
- **3x smaller** memory footprint

The `<=>` operator performs cosine distance (not similarity):

```sql
SELECT part_name, supplier_name
FROM inventory
ORDER BY part_embedding <=> query_vector
LIMIT 1;
```

> **Note:** When using parameterized queries with `%s` placeholders, you must cast: `%s::vector`. Example: `part_embedding <=> %s::vector`

## Sample Data

The database ships with 20 inventory items including boxes, bolts, gaskets, bearings, and more. Each part gets a real 768-dimensional embedding generated by AlloyDB's `ai.embedding()` function.

## Setting Up the Database

### Primary: AlloyDB Studio (Recommended)

Run the SQL blocks from `seed_data.sql` in AlloyDB Studio step by step. See the codelab for detailed instructions.

### Backup: Python Script

```bash
pip install -r requirements.txt
python3 seed.py
```

The script connects via the AlloyDB Python Connector — no Auth Proxy required.

## Connection Details

The backup script uses the AlloyDB Python Connector:

```python
from google.cloud.alloydbconnector import Connector

connector = Connector()
conn = connector.connect(
    inst_uri,         # projects/PROJECT/locations/REGION/clusters/CLUSTER/instances/INSTANCE
    "pg8000",
    user="postgres",
    password=os.environ["DB_PASS"],
    db="postgres",
    ip_type="PUBLIC",  # Use "PRIVATE" for Cloud Run
)
```

## Embedding Generation

Embeddings are generated in AlloyDB using the built-in `ai.embedding()` function:

```sql
UPDATE inventory
SET part_embedding = ai.embedding(
    'text-embedding-005',
    part_name || '. ' || description
)::vector
WHERE part_embedding IS NULL;
```

This calls Vertex AI directly from SQL — no Python code needed.

## Troubleshooting

### AlloyDB not configured

Check your `.env` file has the correct values:
```bash
cat .env | grep ALLOYDB
```

### Connection refused

Ensure AlloyDB Public IP is enabled and your instance is running:
```bash
gcloud alloydb instances list --format="value(name,state)"
```

### Seed script fails

Common issues:
- Wrong password in `.env`
- Public IP not enabled on AlloyDB instance
- AlloyDB instance not ready (wait 1-2 minutes after provisioning)

## Production Considerations

For production deployments:

1. **Use real embeddings**: Generate embeddings from actual part descriptions
2. **Tune ScaNN**: Adjust `num_leaves` based on dataset size (typically sqrt of row count)
3. **Add indexes**: Create indexes on frequently queried columns
4. **Enable replication**: Use AlloyDB read replicas for high availability
5. **Monitor performance**: Use Cloud Monitoring for query latency metrics

## Learn More

- [AlloyDB AI Documentation](https://cloud.google.com/alloydb/docs/ai)
- [AlloyDB Python Connector](https://github.com/GoogleCloudPlatform/alloydb-python-connector)
- [ScaNN Overview](https://cloud.google.com/alloydb/docs/ai/work-with-embeddings)
